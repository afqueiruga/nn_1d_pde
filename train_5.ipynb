{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"train_5.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"eVC42-GXS5eD","colab_type":"code","outputId":"096bcb02-2598-42f8-8e64-74c41c6d18b5","executionInfo":{"status":"ok","timestamp":1567888894901,"user_tz":420,"elapsed":26211,"user":{"displayName":"Alejandro Queiruga","photoUrl":"","userId":"08519531982283031247"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["import sys\n","if True:\n","    from google.colab import drive\n","    drive.mount('/content/drive',force_remount=True)\n","    root = \"/content/drive/My Drive/Colab Notebooks/burgers/\"\n","    sys.path.append(\"/content/drive/My Drive/Colab Notebooks/burgers/\")\n","else:\n","    root = './'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4IUKEjFRS5eJ","colab_type":"code","outputId":"071caed9-f6d1-4e7a-8901-30a3a9ae1ef0","executionInfo":{"status":"ok","timestamp":1567888895295,"user_tz":420,"elapsed":4588,"user":{"displayName":"Alejandro Queiruga","photoUrl":"","userId":"08519531982283031247"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import torch\n","from matplotlib import pylab as plt\n","if torch.cuda.device_count()>0:\n","    device = torch.device('cuda')\n","    print(\"Connected to a GPU\")\n","else:\n","    print(\"Using the CPU\")\n","    device = torch.device('cpu')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Connected to a GPU\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dm048mL6S5eP","colab_type":"code","colab":{}},"source":["loss_L2 = torch.nn.MSELoss()\n","def train_it(dataset, model, disc,Npast=1, Nfuture=1):\n","    #model = model\n","    learning_rate = 1e-4\n","    optim_model = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    optim_disc  = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n","\n","    Nepoch = 10000\n","    Nbatch = 50\n","    Ntotal = dataset.shape[0]*(dataset.shape[1]-(Npast+1)-Nfuture)\n","    Niter = Nepoch * Ntotal//Nbatch\n","    Nprint = (Niter)//10\n","    Nsave = 100\n","    losses = np.zeros((Niter//Nsave,2))\n","    \n","    for e in range(Niter):\n","        xx,yy = get_batch(Nbatch, dataset)\n","        \n","        # Step the discriminator\n","        y_pred = model(xx)+xx\n","        L_D = -0.5*(1 - disc(y_pred,xx).mean() + disc(yy,xx).mean())\n","        optim_disc.zero_grad()\n","        L_D.backward(retain_graph=True)\n","        optim_disc.step()\n","        \n","        # Step the model\n","        L_G = 0.5*(1 - disc(y_pred,xx).mean())\n","        optim_model.zero_grad()\n","        L_G.backward()\n","        optim_model.step()\n","        \n","        #yy[:,:,1:-1]\n","        L2 = loss_L2(y_pred,yy)\n","        if e%Nprint == Nprint-1:\n","            print(e, L_D.item(),L2.item())\n","        if e%Nsave == Nsave-1:\n","            losses[e//Nsave,0] = L_D.item()\n","            losses[e//Nsave,1] = L2.item()\n","    return losses"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"odLsWTIzS5eM","colab_type":"code","colab":{}},"source":["import importlib\n","import util\n","importlib.reload(util)\n","from util import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9krtj8a_3WW","colab_type":"code","colab":{}},"source":["stash = {}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iFujmGBHS8DU","colab_type":"code","outputId":"7a257bdf-b1ab-47f5-b808-59abba7bf113","executionInfo":{"status":"ok","timestamp":1567815338673,"user_tz":420,"elapsed":153899,"user":{"displayName":"Alejandro Queiruga","photoUrl":"","userId":"08519531982283031247"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["for dataname in [\"heat\"]:\n","    data = np.load(root+f\"data/{dataname}.npz\")\n","    dataset = torch.tensor(data['U'],dtype=torch.float32,device=device)\n","    Ntraj,Nt,Nx = dataset.shape\n","    for name, cls in [(\"PureStencil\",PureStencil)]: #models.items():\n","        try:\n","            model =  stash[name]['model']\n","            disc =   stash[name]['disc']\n","            results =stash[name]['loss'] \n","            print(\"Resuming training of \",name)\n","        except KeyError:\n","            model = cls(Nx).to(device)\n","            disc = ConditionalDiscriminatorConv(Nx,1).to(device)\n","            results = np.empty((0,2))\n","            print(\"Training new \",name)\n","        tr_res = train_it(dataset,model,disc)\n","        results = np.append(results, tr_res, axis=0)\n","        stash[name] = {'model':model,\n","                       'disc':disc,\n","                       'loss':results}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training new  PureStencil\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xt0w4NuYUUv5","colab_type":"code","colab":{}},"source":["for N,S in stash.items():\n","    plt.plot(S['loss'][:,0],label=f\"{N}, D\")\n","plt.legend()\n","plt.show()\n","for N,S in stash.items():\n","    plt.semilogy(S['loss'][:,1],label=f\"{N}, L2\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gE4meBQd1H0","colab_type":"code","colab":{}},"source":["err = {}\n","for N,S in stash.items():\n","    print(N)\n","    err[N] = do_a_path(S['model'],dataset,1,-1)\n","for N,e in err.items():\n","    plt.plot(e,label=N)\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r3izsUTvd2j8","colab_type":"code","colab":{}},"source":["list(model.parameters())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZzcRrMx9Qlr","colab_type":"code","colab":{}},"source":["x,y = get_batch(1,dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"acQhGaUnMxAJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6441bf81-d25e-4548-e46c-04fab619f094","executionInfo":{"status":"ok","timestamp":1567884566605,"user_tz":420,"elapsed":203,"user":{"displayName":"Alejandro Queiruga","photoUrl":"","userId":"08519531982283031247"}}},"source":["torch.stack((x,y),dim=1).shape"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 2, 1, 41])"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"YW7r9eZ8M1LA","colab_type":"code","colab":{}},"source":["torch.stack?"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7p4xS_HfM8Dd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"31402f47-5ac0-4626-9afb-fb5f8dd43dd9","executionInfo":{"status":"ok","timestamp":1567884579696,"user_tz":420,"elapsed":287,"user":{"displayName":"Alejandro Queiruga","photoUrl":"","userId":"08519531982283031247"}}},"source":["x.shape"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 1, 41])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8W50kqKeNBHT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}